{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9cc575c",
   "metadata": {},
   "source": [
    "PARTE 1: Abrir a página do pregão que contém as informações básicas e os links para cada item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3792b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fbf6b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "# URL da página do pregão\n",
    "url = \"https://contratos.sistema.gov.br/transparencia/compras?lei=LEI14133&lei_text=LEI14133&unidade_origem_id=9964&unidade_origem_id_text=160224+-+PARQUE+REGIONAL+DE+MANUTENCAO%2F5&modalidade_id=76&modalidade_id_text=05+-+Preg%C3%A3o\"\n",
    "\n",
    "# Obtendo a data atual\n",
    "data_atual = datetime.date.today()\n",
    "\n",
    "def iniciar():\n",
    "    if os.path.exists('url_pregoes.csv'):\n",
    "        try:\n",
    "            url_pregoes_antiga = carregar_lista_pregoes()\n",
    "                        \n",
    "            url_pregoes_nova = baixar_nova_lista_pregoes(url)\n",
    "            \n",
    "            df_itens = verificar_se_ha_novos_pregoes(url_pregoes_antiga, url_pregoes_nova)\n",
    "            \n",
    "            salvar_dados(df_itens)\n",
    "            \n",
    "            return 'Dados Salvos com sucesso!'\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Erro ao carregar lista de pregões: {e}.')\n",
    "    else:\n",
    "        print('Não há lista de pregões salvas nesse computador.')\n",
    "        url_pregoes_antiga = []\n",
    "        \n",
    "        #Baixando lista de pregões\n",
    "        print('Obtendo a url dos pregões...')\n",
    "        url_pregoes_nova = baixar_nova_lista_pregoes(url)\n",
    "        \n",
    "        print('Obtendo a url dos itens...')      \n",
    "        url_itens = obter_url_dos_itens(url_pregoes_nova)\n",
    "        print('URL dos itens obtida com sucesso!') \n",
    "        \n",
    "        print('Obtendo os dados dos itens...')\n",
    "        df_itens = atualizar_todos_os_dados(url_itens)\n",
    "        print('Dados dos itens obtidos com sucesso!')\n",
    "    \n",
    "        salvar_dados(df_itens)\n",
    "        \n",
    "        return 'Dados Salvos com sucesso!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1171da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_lista_pregoes():\n",
    "    nome_arquivo = 'url_pregoes.csv'\n",
    "    url_pregoes_antiga = []\n",
    "    \n",
    "    with open(nome_arquivo, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Pular o cabeçalho\n",
    "        url_pregoes_antiga = [row[0] for row in reader]\n",
    "    \n",
    "    print('Lista de Pregões salvas no PC encontrada!')\n",
    "        \n",
    "    return url_pregoes_antiga\n",
    "\n",
    "def baixar_nova_lista_pregoes(url):\n",
    "    \n",
    "    print('Baixando nova lista de url dos pregões ...')\n",
    "    # Configuração do WebDriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Executar em modo headless para não abrir uma janela do navegador\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Selecionar a opção \"Todos\"\n",
    "    select = Select(driver.find_element(By.NAME, 'crudTable_length'))\n",
    "    select.select_by_value('-1')\n",
    "    time.sleep(5)  # Esperar alguns segundos para garantir que a página carregue completamente\n",
    "\n",
    "    # Obter e parsear o HTML da página\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.quit()\n",
    "\n",
    "    specific_url_part = 'https://contratos.sistema.gov.br/transparencia/compras/'\n",
    "    url_pregoes_nova = [a_tag['href'].replace('show', 'itens') for a_tag in soup.find_all('a', href=True) if specific_url_part in a_tag['href']]\n",
    "    \n",
    "\n",
    "\n",
    "    # Gravar a lista em um arquivo CSV\n",
    "    nome_arquivo = 'url_pregoes.csv'\n",
    "    with open(nome_arquivo, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([f'Atualizado em {data_atual}'])  # Escrever a data da atualização\n",
    "        writer.writerows([[url] for url in url_pregoes_nova])\n",
    "        print('Nova Lista de url dos pregões salva com sucesso!')\n",
    "    \n",
    "    return url_pregoes_nova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a7922e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_se_ha_novos_pregoes(url_pregoes_antiga, url_pregoes_nova):\n",
    "    \n",
    "    novos_pregoes = list(set(url_pregoes_nova) - set(url_pregoes_antiga))\n",
    "    \n",
    "    if novos_pregoes == []:\n",
    "        \n",
    "        print('Não há novos pregões. Iniciando atualização dos saldos...')\n",
    "        \n",
    "            #Carregando df_itens\n",
    "    \n",
    "        print('Carregando DataFrame com os dados dos itens...')\n",
    "\n",
    "        df_itens = pd.read_csv('df_itens.csv', sep=';')\n",
    "        #Para obter as informações de cada item\n",
    "\n",
    "        #chamar função de atualizar o saldo dos pregões existentes\n",
    "    \n",
    "        df_itens = atualizar_saldo(df_itens)\n",
    "        \n",
    "        return df_itens\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('Há novos pregões não cadastrados! \\n Obtendo os dados dos novos pregões...') \n",
    "        \n",
    "        url_itens_novos = obter_url_dos_itens(novos_pregoes)\n",
    "\n",
    "        df_itens_novos = atualizar_todos_os_dados(url_itens_novos)\n",
    "        \n",
    "        print('Dados dos novos pregões atualizados! Atualizando o saldo dos pregões anteriores...')\n",
    "        \n",
    "        \n",
    "        #colocar um try encontrar df_itens salvos\n",
    "        df_itens_antigos = pd.read_csv('df_itens.csv', sep = ';')\n",
    "        \n",
    "        df_itens_antigos = atualizar_saldo(df_itens_antigos)\n",
    "        \n",
    "        print('Saldo dos pregões anteriores atualizado. Concatenando a tabela dos itens antigos com os novos...')\n",
    "        \n",
    "        df_itens = pd.concat([df_itens_novos, df_itens_antigos])\n",
    "        \n",
    "        return df_itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f8432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_dados(df_itens):\n",
    "    \n",
    "    #Salvando o df em arquivo csv\n",
    "    nome_arquivo = \"df_itens.csv\"\n",
    "\n",
    "    # Exportando o DataFrame para um arquivo CSV com delimitador ';' e codificação UTF-8\n",
    "    df_itens.to_csv(nome_arquivo, sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "    print('Arquivo com a tabela dos itens salva com sucesso!')\n",
    "    \n",
    "    #Gravar a lista em um arquivo CSV\n",
    "    \n",
    "    df_itens['Link do Item'].to_csv('url_itens.csv', sep=';', encoding='utf-8', index=False)\n",
    "    \n",
    "    print('Lista com a url dos itens salva com sucesso!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7bf2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_url_dos_itens(novos_pregoes):\n",
    "    \n",
    "    url_itens = []\n",
    "\n",
    "    for url in novos_pregoes:       \n",
    "\n",
    "    # Configuração do WebDriver\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')  # Executar em modo headless para não abrir uma janela do navegador\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(url)\n",
    "\n",
    "        # Encontrar o elemento select pelo ID\n",
    "        select_element = driver.find_element(By.NAME, 'crudTable_length')\n",
    "\n",
    "        # Criar um objeto Select\n",
    "        select = Select(select_element)\n",
    "\n",
    "        # Selecionar a opção \"Todos\"\n",
    "        select.select_by_value('-1')\n",
    "\n",
    "        # Esperar alguns segundos para garantir que a página carregue completamente\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Obter o HTML da página\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Fechar o WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "        # Parsear o HTML com Beautiful Soup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Encontrar os links para cada item\n",
    "        specific_url_part = 'https://contratos.sistema.gov.br/transparencia/compras/'\n",
    "\n",
    "        for a_tag in soup.find_all('a', href=True):\n",
    "            href = a_tag['href']\n",
    "            if specific_url_part in href:\n",
    "                url_itens.append(href)    \n",
    "\n",
    "    url_itens = [url for url in url_itens if 'show' in url]\n",
    "    \n",
    "        \n",
    "    return url_itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de1b1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualizar_todos_os_dados(url_itens):\n",
    "\n",
    "    linhas = []\n",
    "\n",
    "    for url in url_itens:\n",
    "        \n",
    "        # Enviar uma solicitação GET para obter o conteúdo da página\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Verificar se a solicitação foi bem-sucedida\n",
    "\n",
    "        if response.status_code == 200:              \n",
    "\n",
    "            # Parsear o HTML da página com Beautiful Soup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            #Pregão\n",
    "            pregao = soup.find_all('div', class_='header-title')[1].text.strip().replace('Itens da compra: 160224 - ','')\n",
    "\n",
    "            # Encontrar todas as tabelas na página\n",
    "            tables = soup.find_all('table')\n",
    "            #Define a nova linha\n",
    "            linha = [\n",
    "                pregao, #Pregão\n",
    "                tables[0].find_all('span')[0].text.strip(), #Item\n",
    "                tables[0].find_all('span')[2].text.strip(), #Descrição\n",
    "                tables[0].find_all('span')[3].text.strip(), #Descrição detalhada\n",
    "                #tables[0].find_all('span')[4].text.strip(), #Qtd. Total\n",
    "                tables[0].find_all('span')[5].text.strip(), #Vig. Início ARP\n",
    "                tables[0].find_all('span')[6].text.strip(), #Vig. Fim ARP\n",
    "                tables[1].find_all('td')[0].text.strip(), #Unidade\n",
    "                #tables[1].find_all('td')[1].text.strip(), #Tipo UASG\n",
    "                tables[1].find_all('td')[2].text.strip(), #Qtd. Autorizada\n",
    "\n",
    "                tables[2].find_all('td')[0].text.strip(), #Fornecedor\n",
    "                #tables[2].find_all('td')[1].text.strip(), #Qtd. Homologada\n",
    "                tables[2].find_all('td')[2].text.strip(), #Val. Unitário\n",
    "                #tables[2].find_all('td')[3].text.strip(), #Val. Negociado      \n",
    "                tables[1].find_all('td')[3].text.strip(), #Qtd. Saldo\n",
    "                url, #link de cada item no Comprasgov\n",
    "                ]\n",
    "            #Append a linha\n",
    "            linhas.append(linha)\n",
    "            \n",
    "    #Para obter os cabeçalhos\n",
    "\n",
    "    headers = [\n",
    "        \"Número da Compra\",\n",
    "        tables[0].find_all('strong')[0].text.strip(), #Item\n",
    "        tables[0].find_all('strong')[2].text.strip(), #Descrição\n",
    "        tables[0].find_all('strong')[3].text.strip(), #Descrição detalhada\n",
    "        #tables[0].find_all('strong')[4].text.strip(), #Qtd. Total\n",
    "        tables[0].find_all('strong')[5].text.strip(), #Vig. Início ARP\n",
    "        tables[0].find_all('strong')[6].text.strip(), #Vig. Fim ARP\n",
    "        tables[1].find_all('th')[0].text.strip(), #Unidade\n",
    "        #tables[1].find_all('th')[1].text.strip(), #Tipo UASG\n",
    "        tables[1].find_all('th')[2].text.strip(), #Qtd. Autorizada\n",
    "\n",
    "        tables[2].find_all('th')[0].text.strip(), #Fornecedor\n",
    "        #tables[2].find_all('th')[1].text.strip(), #Qtd. Homologada\n",
    "        tables[2].find_all('th')[2].text.strip(), #Val. Unitário\n",
    "        #tables[2].find_all('th')[3].text.strip(), #Val. Negociado\n",
    "        tables[1].find_all('th')[3].text.strip(), #Qtd. Saldo\n",
    "        'Link do Item'\n",
    "    ]\n",
    "\n",
    "    headers[1] = \"Número do Item\"\n",
    "    headers[2] = \"Descrição\"\n",
    "    headers[3] = \"Descrição Detalhada\"\n",
    "    headers[4] = \"Início da Vigência\"\n",
    "    headers[5] = \"Fim da Vigência\"\n",
    "\n",
    "    #transformando os dados em um dataframe\n",
    "\n",
    "    df_itens = pd.DataFrame(linhas, columns = headers)\n",
    "\n",
    "    #Corrigindo os valores que são numéricos\n",
    "\n",
    "    df_itens['Qtd. Autorizada'] = df_itens['Qtd. Autorizada'].str.replace('.','')\n",
    "    df_itens['Qtd. Autorizada'] = df_itens['Qtd. Autorizada'].str.replace(',','.')\n",
    "\n",
    "    df_itens['Val. Unitário'] = df_itens['Val. Unitário'].str.replace('.','')\n",
    "    df_itens['Val. Unitário'] = df_itens['Val. Unitário'].str.replace(',','.')\n",
    "\n",
    "    df_itens['Qtd. Saldo'] = df_itens['Qtd. Saldo'].str.replace('.','')\n",
    "    df_itens['Qtd. Saldo'] = df_itens['Qtd. Saldo'].str.replace(',','.')\n",
    "\n",
    "    #Inserindo novas colunas\n",
    "\n",
    "    tipo_compra = []\n",
    "    numero_compra_pregao = []\n",
    "    ano_compra_pregao = []\n",
    "\n",
    "\n",
    "    for i in range(len(df_itens['Número da Compra'])):\n",
    "        tipo = df_itens['Número da Compra'][i].split(' ')[0]\n",
    "        numero_pregao = df_itens['Número da Compra'][i].split(' ')[2].split('/')[0]\n",
    "        ano_pregao = df_itens['Número da Compra'][i].split(' ')[2].split('/')[1]\n",
    "\n",
    "        tipo_compra.append(tipo)\n",
    "        numero_compra_pregao.append(numero_pregao)\n",
    "        ano_compra_pregao.append(ano_pregao)\n",
    "\n",
    "    df_itens['Tipo de Compra'] = tipo_compra\n",
    "    df_itens['Número do Pregão'] = numero_compra_pregao\n",
    "    df_itens['Ano do Pregão'] = ano_compra_pregao\n",
    "\n",
    "    return df_itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dda49ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualizar_saldo(df_itens):\n",
    "    \n",
    "#atualizando o saldo\n",
    "    \n",
    "    for i in range(len(df_itens['Link do Item'])):\n",
    "        \n",
    "        url = df_itens['Link do Item'][i]\n",
    "        \n",
    "        # Enviar uma solicitação GET para obter o conteúdo da página\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Verificar se a solicitação foi bem-sucedida\n",
    "    \n",
    "        if response.status_code == 200:  \n",
    "\n",
    "            # Parsear o HTML da página com Beautiful Soup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Encontrar todas as tabelas na página\n",
    "            tables = soup.find_all('table')\n",
    "\n",
    "            #Define a nova linha\n",
    "            saldo = tables[1].find_all('td')[3].text.strip() #Qtd. Saldo\n",
    "\n",
    "            #Gravar saldo\n",
    "            df_itens['Qtd. Saldo'][i] = saldo\n",
    "\n",
    "            print('Saldo do item ' + str(i) + ' atualizado com sucesso!')\n",
    "\n",
    "    df_itens['Qtd. Saldo'] = df_itens['Qtd. Saldo'].str.replace('.','')\n",
    "    df_itens['Qtd. Saldo'] = df_itens['Qtd. Saldo'].str.replace(',','.')\n",
    "    \n",
    "    return df_itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbca7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    iniciar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e64b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
