{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9cc575c",
   "metadata": {},
   "source": [
    "PARTE 1: Abrir a página do pregão que contém as informações básicas e os links para cada item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3792b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf6b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL da página do pregão\n",
    "url = \"https://contratos.sistema.gov.br/transparencia/compras?lei=LEI14133&lei_text=LEI14133&unidade_origem_id=9964&unidade_origem_id_text=160224+-+PARQUE+REGIONAL+DE+MANUTENCAO%2F5&modalidade_id=76&modalidade_id_text=05+-+Preg%C3%A3o\"\n",
    "\n",
    "# Obtendo a data atual\n",
    "data_atual = datetime.date.today()\n",
    "\n",
    "def iniciar():\n",
    "    if os.path.exists('url_pregoes.csv'):\n",
    "        try:\n",
    "            url_pregoes_antiga = carregar_lista_pregoes()\n",
    "                        \n",
    "            url_pregoes_nova = baixar_nova_lista_pregoes(url)\n",
    "            \n",
    "            df_itens = verificar_se_ha_novos_pregoes(url_pregoes_antiga, url_pregoes_nova)\n",
    "            \n",
    "            salvar_dados(df_itens)\n",
    "            \n",
    "            return 'Dados Salvos com sucesso!'\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Erro ao carregar lista de pregões: {e}.')\n",
    "    else:\n",
    "        print('Não há lista de pregões salvas nesse computador.')\n",
    "        url_pregoes_antiga = []\n",
    "        \n",
    "        #Baixando lista de pregões\n",
    "        print('Obtendo a url dos pregões...')\n",
    "        url_pregoes_nova = baixar_nova_lista_pregoes(url)\n",
    "        \n",
    "        print('Obtendo a url dos itens...')      \n",
    "        url_itens = obter_url_dos_itens(url_pregoes_nova)\n",
    "        \n",
    "        print('URL dos itens obtida com sucesso!') \n",
    "        \n",
    "        print('Obtendo os dados dos itens...')\n",
    "        df_itens = atualizar_todos_os_dados(url_itens)\n",
    "        \n",
    "        print('Dados dos itens obtidos com sucesso!')\n",
    "    \n",
    "        salvar_dados(df_itens)\n",
    "        \n",
    "        return 'Dados Salvos com sucesso!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1171da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_lista_pregoes():\n",
    "    nome_arquivo = 'url_pregoes.csv'\n",
    "    url_pregoes_antiga = []\n",
    "    \n",
    "    with open(nome_arquivo, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Pular o cabeçalho\n",
    "        url_pregoes_antiga = [row[0] for row in reader]\n",
    "    \n",
    "    print('Lista de Pregões salvas no PC encontrada!')\n",
    "        \n",
    "    return url_pregoes_antiga\n",
    "\n",
    "def baixar_nova_lista_pregoes(url):\n",
    "    \n",
    "    print('Baixando nova lista de url dos pregões ...')\n",
    "    # Configuração do WebDriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Executar em modo headless para não abrir uma janela do navegador\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Selecionar a opção \"Todos\"\n",
    "    select = Select(driver.find_element(By.NAME, 'crudTable_length'))\n",
    "    select.select_by_value('-1')\n",
    "    time.sleep(5)  # Esperar alguns segundos para garantir que a página carregue completamente\n",
    "\n",
    "    # Obter e parsear o HTML da página\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.quit()\n",
    "\n",
    "    specific_url_part = 'https://contratos.sistema.gov.br/transparencia/compras/'\n",
    "    url_pregoes_nova = [a_tag['href'].replace('show', 'itens') for a_tag in soup.find_all('a', href=True) if specific_url_part in a_tag['href']]\n",
    "    \n",
    "\n",
    "\n",
    "    # Gravar a lista em um arquivo CSV\n",
    "    nome_arquivo = 'url_pregoes.csv'\n",
    "    with open(nome_arquivo, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([f'Atualizado em {data_atual}'])  # Escrever a data da atualização\n",
    "        writer.writerows([[url] for url in url_pregoes_nova])\n",
    "        print('Nova Lista de url dos pregões salva com sucesso!')\n",
    "    \n",
    "    return url_pregoes_nova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a7922e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_se_ha_novos_pregoes(url_pregoes_antiga, url_pregoes_nova):\n",
    "    \n",
    "    novos_pregoes = list(set(url_pregoes_nova) - set(url_pregoes_antiga))\n",
    "    \n",
    "    if novos_pregoes == []:\n",
    "        \n",
    "        print('Não há novos pregões. Iniciando atualização dos saldos...')\n",
    "        \n",
    "            #Carregando df_itens\n",
    "    \n",
    "        print('Carregando DataFrame com os dados dos itens...')\n",
    "\n",
    "        df_itens = pd.read_csv('df_itens_gerenciadora.csv', sep=';')\n",
    "        #Para obter as informações de cada item\n",
    "\n",
    "        #chamar função de atualizar o saldo dos pregões existentes\n",
    "    \n",
    "        df_itens = atualizar_saldo(df_itens)\n",
    "        \n",
    "        return df_itens\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('Há novos pregões não cadastrados! \\n Obtendo os dados dos novos pregões...') \n",
    "        \n",
    "        url_itens_novos = obter_url_dos_itens(novos_pregoes)\n",
    "\n",
    "        df_itens_novos = atualizar_todos_os_dados(url_itens_novos)\n",
    "\n",
    "  \n",
    "        print('Dados dos novos pregões atualizados! Atualizando o saldo dos pregões anteriores...')\n",
    "        \n",
    "        \n",
    "        #colocar um try encontrar df_itens salvos\n",
    "\n",
    "        try:\n",
    "            \n",
    "            df_itens_antigos = pd.read_csv('df_itens_gerenciadora.csv', sep = ';')\n",
    "            \n",
    "            df_itens_antigos = atualizar_saldo(df_itens_antigos)\n",
    "            \n",
    "            print('Saldo dos pregões anteriores atualizado. Concatenando a tabela dos itens antigos com os novos...')\n",
    "            \n",
    "            df_itens = pd.concat([df_itens_novos, df_itens_antigos])\n",
    "        \n",
    "            return df_itens\n",
    "\n",
    "        except:\n",
    "\n",
    "            df_itens = df_itens_novos\n",
    "\n",
    "            return df_itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47bc8672-0927-4c90-9647-f67600e0d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_unidade_objeto(df_itens_novos):\n",
    "    \n",
    "    #Obtendo as novas URL dos pregões\n",
    "\n",
    "    lista_pregao_site_antigo = []\n",
    "    \n",
    "    for i in range(len(df_itens_novos)):\n",
    "      url = \"http://comprasnet.gov.br/ConsultaLicitacoes/download/download_editais_detalhe.asp?coduasg=\" + str(df_itens_novos['UASG'][i])+\"&modprp=5&numprp=\" + str(df_itens_novos['Número do Pregão'][i]) + str(df_itens_novos['Ano do Pregão'][i])\n",
    "      lista_pregao_site_antigo.append(url)\n",
    "    \n",
    "    lista_pregao_site_antigo = list(dict.fromkeys(lista_pregao_site_antigo))\n",
    "\n",
    "    #obter os dados do pregão na primeira página\n",
    "\n",
    "    linhas = []\n",
    "    \n",
    "    for url in lista_pregao_site_antigo:\n",
    "    \n",
    "        #Abrindo a página desejada\n",
    "    \n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "        #options = webdriver.ChromeOptions()\n",
    "        #options.add_argument('--headless')  # Executar em modo headless para não abrir uma janela do navegador\n",
    "        time.sleep(5)  # Aguarde a página carregar\n",
    "    \n",
    "        for i in range(len(driver.find_elements(By.XPATH, \"//span[@class='tex3b']\")[2:-1])):\n",
    "            \n",
    "            numeropregao_ano = driver.find_elements(By.XPATH, \"//span[@class='tex3b']\")[0].text.split('Nº')[1].strip()\n",
    "            objeto = driver.find_element(By.XPATH, \"//p[contains(text(),'Objeto:')]\").text.split('\\n')[1]\n",
    "            numero_item = driver.find_elements(By.XPATH, \"//span[@class='tex3b']\")[i+2].text.split('-')[0].strip()\n",
    "            descricao_item = driver.find_elements(By.XPATH, \"//span[@class='tex3b']\")[i+2].text.split('-')[1].strip()\n",
    "            descricao_complementar = driver.find_elements(By.XPATH, \"//span[@class='tex3']\")[i].text.split('\\n')[0]\n",
    "            unidade_medida = driver.find_elements(By.XPATH, \"//span[@class='tex3']\")[i].text.split('\\n')[5].split(':')[1].strip()\n",
    "        \n",
    "            dados = [numeropregao_ano, objeto, numero_item, descricao_item, descricao_complementar, unidade_medida]\n",
    "            \n",
    "            linhas.append(dados)\n",
    "    \n",
    "        \n",
    "        #verificar se tem próxima página para obter os dados\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # Tente encontrar o botão \"Próxima\" e clique nele\n",
    "                next_button = driver.find_element(By.ID, \"proximas\").click()\n",
    "                \n",
    "                time.sleep(5)  # Aguarde a página carregar\n",
    "                \n",
    "                for i in range(len(driver.find_elements(By.XPATH, \"//span[@class='tex3b']\")[2:-1])):\n",
    "                    \n",
    "                    numeropregao_ano = driver.find_elements(By.XPATH, \"//span[@class='tex3b']\")[0].text.split('Nº')[1].strip()\n",
    "                    objeto = driver.find_element(By.XPATH, \"//p[contains(text(),'Objeto:')]\").text.split('\\n')[1]\n",
    "                    numero_item = driver.find_elements(By.XPATH, \"//span[@class='tex3b']\")[i+2].text.split('-')[0].strip()\n",
    "                    descricao_item = driver.find_elements(By.XPATH, \"//span[@class='tex3b']\")[i+2].text.split('-')[1].strip()\n",
    "                    descricao_complementar = driver.find_elements(By.XPATH, \"//span[@class='tex3']\")[i].text.split('\\n')[0]\n",
    "                    unidade_medida = driver.find_elements(By.XPATH, \"//span[@class='tex3']\")[i].text.split('\\n')[5].split(':')[1].strip()\n",
    "                \n",
    "                    dados = [numeropregao_ano, objeto, numero_item, descricao_item, descricao_complementar, unidade_medida]\n",
    "                    \n",
    "                    linhas.append(dados)\n",
    "                    \n",
    "            except:\n",
    "                # Fechar o WebDriver\n",
    "                driver.quit()\n",
    "                # Se não encontrar o botão \"Próxima\", saia do loop\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    #Cabeçalho\n",
    "    headers = [\"Número da Compra\",\"Objeto\",\"Número do Item\",\"Descrição\", \"Descrição Complementar\",\"Unidade de Fornecimento\"]\n",
    "    \n",
    "    \n",
    "    #transformando os dados em dataframe\n",
    "    df_itens_novos_site_antigo = pd.DataFrame(linhas, columns = headers)\n",
    "\n",
    "    #apagar\n",
    "    print('imprimir df_itens_novos_site_antigo')\n",
    "    display(df_itens_novos_site_antigo)\n",
    "    \n",
    "    #obtendo o número do pregão e o ano\n",
    "    \n",
    "    ano_pregao = []\n",
    "    numero_pregao = []\n",
    "    \n",
    "    for i in range(len(df_itens_novos_site_antigo['Número da Compra'])):\n",
    "        \n",
    "        numero = df_itens_novos_site_antigo['Número da Compra'][i].split('/')[0]\n",
    "        numero_pregao.append(numero)\n",
    "        \n",
    "        ano = df_itens_novos_site_antigo['Número da Compra'][i].split('/')[1]\n",
    "        ano_pregao.append(ano)\n",
    "    \n",
    "    df_itens_novos_site_antigo['Ano do Pregão'] = ano_pregao\n",
    "    df_itens_novos_site_antigo['Número do Pregão'] = numero_pregao\n",
    "    \n",
    "    df_itens_novos_site_antigo['Ano do Pregão'] = df_itens_novos_site_antigo['Ano do Pregão'].astype(int)\n",
    "    df_itens_novos_site_antigo['Ano do Pregão'] = df_itens_novos_site_antigo['Ano do Pregão'].astype('string')\n",
    "    \n",
    "    df_itens_novos_site_antigo['Número do Pregão'] = df_itens_novos_site_antigo['Número do Pregão'].astype(int)\n",
    "    df_itens_novos_site_antigo['Número do Pregão'] = df_itens_novos_site_antigo['Número do Pregão'].astype('string')\n",
    "\n",
    "    df_itens_novos_site_antigo['Número do Item'] = df_itens_novos_site_antigo['Número do Item'].astype(int)\n",
    "    df_itens_novos_site_antigo['Número do Item'] = df_itens_novos_site_antigo['Número do Item'].astype('string')\n",
    "\n",
    "    return df_itens_novos_site_antigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83f8432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_dados(df_itens):\n",
    "    \n",
    "    #Salvando o df em arquivo csv\n",
    "    nome_arquivo = \"df_itens_gerenciadora.csv\"\n",
    "\n",
    "    # Exportando o DataFrame para um arquivo CSV com delimitador ';' e codificação UTF-8\n",
    "    df_itens.to_csv(nome_arquivo, sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "    print('Arquivo com a tabela dos itens salva com sucesso!')\n",
    "    \n",
    "    #Gravar a lista em um arquivo CSV\n",
    "    \n",
    "    df_itens['Link do Item'].to_csv('url_itens.csv', sep=';', encoding='utf-8', index=False)\n",
    "    \n",
    "    print('Lista com a url dos itens salva com sucesso!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7bf2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_url_dos_itens(novos_pregoes):\n",
    "    \n",
    "    url_itens = []\n",
    "\n",
    "    for url in novos_pregoes:       \n",
    "\n",
    "    # Configuração do WebDriver\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')  # Executar em modo headless para não abrir uma janela do navegador\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(url)\n",
    "\n",
    "        # Encontrar o elemento select pelo ID\n",
    "        select_element = driver.find_element(By.NAME, 'crudTable_length')\n",
    "\n",
    "        # Criar um objeto Select\n",
    "        select = Select(select_element)\n",
    "\n",
    "        # Selecionar a opção \"Todos\"\n",
    "        select.select_by_value('-1')\n",
    "\n",
    "        # Esperar alguns segundos para garantir que a página carregue completamente\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Obter o HTML da página\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Fechar o WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "        # Parsear o HTML com Beautiful Soup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Encontrar os links para cada item\n",
    "        specific_url_part = 'https://contratos.sistema.gov.br/transparencia/compras/'\n",
    "\n",
    "        for a_tag in soup.find_all('a', href=True):\n",
    "            href = a_tag['href']\n",
    "            if specific_url_part in href:\n",
    "                url_itens.append(href)    \n",
    "\n",
    "    url_itens = [url for url in url_itens if 'show' in url]\n",
    "\n",
    "    # Gravar a lista em um arquivo CSV\n",
    "    nome_arquivo = 'url_itens.csv'\n",
    "    with open(nome_arquivo, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([f'Atualizado em {data_atual}'])  # Escrever a data da atualização\n",
    "        writer.writerows([[url] for url in url_itens])\n",
    "        print('Nova Lista de url dos itens salva com sucesso!')\n",
    "    \n",
    "        \n",
    "    return url_itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de1b1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualizar_todos_os_dados(url_itens):\n",
    "\n",
    "    linhas = []\n",
    "\n",
    "    for url in url_itens:\n",
    "        \n",
    "        # Enviar uma solicitação GET para obter o conteúdo da página\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Verificar se a solicitação foi bem-sucedida\n",
    "\n",
    "        if response.status_code == 200:              \n",
    "\n",
    "            # Parsear o HTML da página com Beautiful Soup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            #Pregão\n",
    "            pregao = soup.find_all('div', class_='header-title')[1].text.strip().replace('Itens da compra: 160224 - ','')\n",
    "\n",
    "            # Encontrar todas as tabelas na página\n",
    "            tables = soup.find_all('table')\n",
    "            #Define a nova linha\n",
    "            linha = [\n",
    "                pregao, #Pregão\n",
    "                tables[0].find_all('span')[0].text.strip(), #Item\n",
    "                tables[0].find_all('span')[2].text.strip(), #Descrição\n",
    "                tables[0].find_all('span')[3].text.strip(), #Descrição detalhada\n",
    "                #tables[0].find_all('span')[4].text.strip(), #Qtd. Total\n",
    "                tables[0].find_all('span')[5].text.strip(), #Vig. Início ARP\n",
    "                tables[0].find_all('span')[6].text.strip(), #Vig. Fim ARP\n",
    "                tables[1].find_all('td')[0].text.strip(), #Unidade\n",
    "                #tables[1].find_all('td')[1].text.strip(), #Tipo UASG\n",
    "                tables[1].find_all('td')[2].text.strip(), #Qtd. Autorizada\n",
    "\n",
    "                tables[2].find_all('td')[0].text.strip(), #Fornecedor\n",
    "                #tables[2].find_all('td')[1].text.strip(), #Qtd. Homologada\n",
    "                tables[2].find_all('td')[2].text.strip(), #Val. Unitário\n",
    "                #tables[2].find_all('td')[3].text.strip(), #Val. Negociado      \n",
    "                tables[1].find_all('td')[3].text.strip(), #Qtd. Saldo\n",
    "                url, #link de cada item no Comprasgov\n",
    "                ]\n",
    "            #Append a linha\n",
    "            linhas.append(linha)\n",
    "            \n",
    "    #Para obter os cabeçalhos\n",
    "\n",
    "    headers = [\n",
    "        \"Número da Compra\",\n",
    "        tables[0].find_all('strong')[0].text.strip(), #Item\n",
    "        tables[0].find_all('strong')[2].text.strip(), #Descrição\n",
    "        tables[0].find_all('strong')[3].text.strip(), #Descrição detalhada\n",
    "        #tables[0].find_all('strong')[4].text.strip(), #Qtd. Total\n",
    "        tables[0].find_all('strong')[5].text.strip(), #Vig. Início ARP\n",
    "        tables[0].find_all('strong')[6].text.strip(), #Vig. Fim ARP\n",
    "        tables[1].find_all('th')[0].text.strip(), #Unidade\n",
    "        #tables[1].find_all('th')[1].text.strip(), #Tipo UASG\n",
    "        tables[1].find_all('th')[2].text.strip(), #Qtd. Autorizada\n",
    "\n",
    "        tables[2].find_all('th')[0].text.strip(), #Fornecedor\n",
    "        #tables[2].find_all('th')[1].text.strip(), #Qtd. Homologada\n",
    "        tables[2].find_all('th')[2].text.strip(), #Val. Unitário\n",
    "        #tables[2].find_all('th')[3].text.strip(), #Val. Negociado\n",
    "        tables[1].find_all('th')[3].text.strip(), #Qtd. Saldo\n",
    "        'Link do Item'\n",
    "    ]\n",
    "\n",
    "    headers[1] = \"Número do Item\"\n",
    "    headers[2] = \"Descrição\"\n",
    "    headers[3] = \"Descrição Detalhada\"\n",
    "    headers[4] = \"Início da Vigência\"\n",
    "    headers[5] = \"Fim da Vigência\"\n",
    "\n",
    "    #transformando os dados em um dataframe\n",
    "\n",
    "    df_itens_novos = pd.DataFrame(linhas, columns = headers)\n",
    "\n",
    "    #Corrigindo os valores que são numéricos\n",
    "\n",
    "    df_itens_novos['Qtd. Autorizada'] = df_itens_novos['Qtd. Autorizada'].str.replace('.','')\n",
    "    df_itens_novos['Qtd. Autorizada'] = df_itens_novos['Qtd. Autorizada'].str.replace(',','.')\n",
    "\n",
    "    df_itens_novos['Val. Unitário'] = df_itens_novos['Val. Unitário'].str.replace('.','')\n",
    "    df_itens_novos['Val. Unitário'] = df_itens_novos['Val. Unitário'].str.replace(',','.')\n",
    "\n",
    "    df_itens_novos['Qtd. Saldo'] = df_itens_novos['Qtd. Saldo'].str.replace('.','')\n",
    "    df_itens_novos['Qtd. Saldo'] = df_itens_novos['Qtd. Saldo'].str.replace(',','.')\n",
    "\n",
    "    \n",
    "    #Inserindo novas colunas\n",
    "\n",
    "    tipo_compra = []\n",
    "    numero_compra_pregao = []\n",
    "    ano_compra_pregao = []\n",
    "\n",
    "\n",
    "    for i in range(len(df_itens_novos['Número da Compra'])):\n",
    "        tipo = df_itens_novos['Número da Compra'][i].split(' ')[0]\n",
    "        numero_pregao = df_itens_novos['Número da Compra'][i].split(' ')[2].split('/')[0]\n",
    "        ano_pregao = df_itens_novos['Número da Compra'][i].split(' ')[2].split('/')[1]\n",
    "        \n",
    "\n",
    "        tipo_compra.append(tipo)\n",
    "        numero_compra_pregao.append(numero_pregao)\n",
    "        ano_compra_pregao.append(ano_pregao)\n",
    "        \n",
    "\n",
    "    df_itens_novos['Tipo de Compra'] = tipo_compra\n",
    "    df_itens_novos['Número do Pregão'] = numero_compra_pregao\n",
    "    df_itens_novos['Ano do Pregão'] = ano_compra_pregao\n",
    "    df_itens_novos['UASG'] = df_itens_novos['Unidade'].str[:6]\n",
    "\n",
    "    #corrigindo o tipo\n",
    "    df_itens_novos['Número do Item'] = df_itens_novos['Número do Item'].astype(int)\n",
    "    df_itens_novos['Número do Item'] = df_itens_novos['Número do Item'].astype('string')\n",
    "    \n",
    "    df_itens_novos['Número do Pregão'] = df_itens_novos['Número do Pregão'].astype(int)\n",
    "    df_itens_novos['Número do Pregão'] = df_itens_novos['Número do Pregão'].astype('string')\n",
    "    \n",
    "    df_itens_novos['Ano do Pregão'] = df_itens_novos['Ano do Pregão'].astype(int)\n",
    "    df_itens_novos['Ano do Pregão'] = df_itens_novos['Ano do Pregão'].astype('string')\n",
    "\n",
    "    #apagar\n",
    "    print('imprimir df_itens_novos')\n",
    "    display(df_itens_novos)\n",
    "\n",
    "    #Função para obter a unidade de fornecimento e objeto a partir do site antigo\n",
    "    \n",
    "    df_itens_novos_site_antigo = obter_unidade_objeto(df_itens_novos)\n",
    "\n",
    "\n",
    "\n",
    "    df_itens_novos = merge_df(df_itens_novos,df_itens_novos_site_antigo)\n",
    "\n",
    "    return df_itens_novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a186b425-d89b-4d22-a4b2-a3d376a3f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(df_itens_novos,df_itens_novos_site_antigo):\n",
    "    \n",
    "    #Criando novas colunas que servirão como key para o merge\n",
    "    df_itens_novos['key'] = df_itens_novos['Número do Pregão'] + '_' + df_itens_novos['Ano do Pregão'] + '_' + df_itens_novos['Número do Item']\n",
    "    df_itens_novos_site_antigo['key'] = df_itens_novos_site_antigo['Número do Pregão'] + '_' + df_itens_novos_site_antigo['Ano do Pregão']+ '_' + df_itens_novos_site_antigo['Número do Item']\n",
    "\n",
    "\n",
    "    #apagar\n",
    "\n",
    "    display(df_itens_novos['key'])\n",
    "    display(df_itens_novos_site_antigo['key'])\n",
    "    \n",
    "    #obtendo o df final\n",
    "\n",
    "    \n",
    "    df_itens_novos = df_itens_novos.merge(df_itens_novos_site_antigo, how = 'left', on = ['key'])\n",
    "\n",
    "\n",
    "    \n",
    "    df_itens_novos = df_itens_novos.drop(columns=['key',\n",
    "                                                    'Número da Compra_y',\n",
    "                                                  'Número do Item_y',\n",
    "                                                  'Descrição_y',\n",
    "                                                  'Descrição Complementar',\n",
    "                                                  'Ano do Pregão_y', \n",
    "                                                  'Número do Pregão_y'])\n",
    "    \n",
    "    df_itens_novos.columns = ['Número da Compra', 'Número do Item', 'Descrição',\n",
    "           'Descrição Detalhada', 'Início da Vigência', 'Fim da Vigência',\n",
    "           'Unidade', 'Qtd. Autorizada', 'Fornecedor', 'Val. Unitário',\n",
    "           'Qtd. Saldo', 'Link do Item', 'Tipo de Compra', 'Número do Pregão',\n",
    "           'Ano do Pregão', 'UASG', 'Objeto','Unidade de Fornecimento',]\n",
    "\n",
    "    df_itens_novos['Descrição'] = df_itens_novos['Descrição'].str.replace(';',',')\n",
    "    df_itens_novos['Descrição Detalhada'] = df_itens_novos['Descrição Detalhada'].str.replace(';',',')\n",
    "    df_itens_novos['Objeto'] = df_itens_novos['Objeto'].str.replace(';',',')\n",
    "    df_itens_novos['Unidade de Fornecimento'] = df_itens_novos['Unidade de Fornecimento'].str.replace(';',',')\n",
    "\n",
    "    return df_itens_novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dda49ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualizar_saldo(df_itens):\n",
    "    \n",
    "#atualizando o saldo\n",
    "    \n",
    "    for i in range(len(df_itens['Link do Item'])):\n",
    "        \n",
    "        url = df_itens['Link do Item'][i]\n",
    "        \n",
    "        # Enviar uma solicitação GET para obter o conteúdo da página\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Verificar se a solicitação foi bem-sucedida\n",
    "    \n",
    "        if response.status_code == 200:  \n",
    "\n",
    "            # Parsear o HTML da página com Beautiful Soup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Encontrar todas as tabelas na página\n",
    "            tables = soup.find_all('table')\n",
    "\n",
    "            #Define a nova linha\n",
    "            saldo = tables[1].find_all('td')[3].text.strip() #Qtd. Saldo\n",
    "\n",
    "            #Gravar saldo\n",
    "            df_itens['Qtd. Saldo'][i] = saldo\n",
    "\n",
    "            print('Saldo do item ' + str(i) + ' atualizado com sucesso!')\n",
    "\n",
    "    df_itens['Qtd. Saldo'] = df_itens['Qtd. Saldo'].str.replace('.','')\n",
    "    df_itens['Qtd. Saldo'] = df_itens['Qtd. Saldo'].str.replace(',','.')\n",
    "    \n",
    "    return df_itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fbca7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não há lista de pregões salvas nesse computador.\n",
      "Obtendo a url dos pregões...\n",
      "Baixando nova lista de url dos pregões ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error managing chromedriver (error sending request for url (https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json)); using driver found in the cache\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[name=\"crudTable_length\"]\"}\n  (Session info: chrome-headless-shell=126.0.6478.116); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF76EEEEEA2+31554]\n\t(No symbol) [0x00007FF76EE67ED9]\n\t(No symbol) [0x00007FF76ED2872A]\n\t(No symbol) [0x00007FF76ED78434]\n\t(No symbol) [0x00007FF76ED7853C]\n\t(No symbol) [0x00007FF76EDBF6A7]\n\t(No symbol) [0x00007FF76ED9D06F]\n\t(No symbol) [0x00007FF76EDBC977]\n\t(No symbol) [0x00007FF76ED9CDD3]\n\t(No symbol) [0x00007FF76ED6A33B]\n\t(No symbol) [0x00007FF76ED6AED1]\n\tGetHandleVerifier [0x00007FF76F1F8B1D+3217341]\n\tGetHandleVerifier [0x00007FF76F245AE3+3532675]\n\tGetHandleVerifier [0x00007FF76F23B0E0+3489152]\n\tGetHandleVerifier [0x00007FF76EF9E776+750614]\n\t(No symbol) [0x00007FF76EE7375F]\n\t(No symbol) [0x00007FF76EE6EB14]\n\t(No symbol) [0x00007FF76EE6ECA2]\n\t(No symbol) [0x00007FF76EE5E16F]\n\tBaseThreadInitThunk [0x00007FFEC7127344+20]\n\tRtlUserThreadStart [0x00007FFEC875CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43miniciar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m, in \u001b[0;36miniciar\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#Baixando lista de pregões\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObtendo a url dos pregões...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m url_pregoes_nova \u001b[38;5;241m=\u001b[39m \u001b[43mbaixar_nova_lista_pregoes\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObtendo a url dos itens...\u001b[39m\u001b[38;5;124m'\u001b[39m)      \n\u001b[0;32m     31\u001b[0m url_itens \u001b[38;5;241m=\u001b[39m obter_url_dos_itens(url_pregoes_nova)\n",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m, in \u001b[0;36mbaixar_nova_lista_pregoes\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     21\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Selecionar a opção \"Todos\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m select \u001b[38;5;241m=\u001b[39m Select(\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcrudTable_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     25\u001b[0m select\u001b[38;5;241m.\u001b[39mselect_by_value(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Esperar alguns segundos para garantir que a página carregue completamente\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[name=\"crudTable_length\"]\"}\n  (Session info: chrome-headless-shell=126.0.6478.116); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF76EEEEEA2+31554]\n\t(No symbol) [0x00007FF76EE67ED9]\n\t(No symbol) [0x00007FF76ED2872A]\n\t(No symbol) [0x00007FF76ED78434]\n\t(No symbol) [0x00007FF76ED7853C]\n\t(No symbol) [0x00007FF76EDBF6A7]\n\t(No symbol) [0x00007FF76ED9D06F]\n\t(No symbol) [0x00007FF76EDBC977]\n\t(No symbol) [0x00007FF76ED9CDD3]\n\t(No symbol) [0x00007FF76ED6A33B]\n\t(No symbol) [0x00007FF76ED6AED1]\n\tGetHandleVerifier [0x00007FF76F1F8B1D+3217341]\n\tGetHandleVerifier [0x00007FF76F245AE3+3532675]\n\tGetHandleVerifier [0x00007FF76F23B0E0+3489152]\n\tGetHandleVerifier [0x00007FF76EF9E776+750614]\n\t(No symbol) [0x00007FF76EE7375F]\n\t(No symbol) [0x00007FF76EE6EB14]\n\t(No symbol) [0x00007FF76EE6ECA2]\n\t(No symbol) [0x00007FF76EE5E16F]\n\tBaseThreadInitThunk [0x00007FFEC7127344+20]\n\tRtlUserThreadStart [0x00007FFEC875CC91+33]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    iniciar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6fe49-658f-4a49-a875-082c578da34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
